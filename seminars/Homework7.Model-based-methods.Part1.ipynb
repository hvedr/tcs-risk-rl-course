{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рисковый курс по обучению с подкреплением. \n",
    "### Занятие 7. Модельные методы. Линейные среды. LQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import display,clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Среда Роборука\n",
    "\n",
    "Роборука имеет 2 шарнира, положение которых задано углами s[0] и s[1]. Скорость изменения углов задана s[2] и s[3], где s - вектор состояния.\n",
    "\n",
    "Контроллер u[0] и u[1] линейно воздействует на скорость.\n",
    "\n",
    "В начале эпизода положение целевого положения манипулятора (серый) выбирается случайно\n",
    "\n",
    "Задача заключается в том, чтобы синий (управляемый) и серый (целевой) манипуляторы находились в одном положении.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class RoboHand():\n",
    "    \n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "        \n",
    "#     class ActionSpace():        \n",
    "        \n",
    "#         def __init__(self):\n",
    "#             self.n = 2 # accelerate two angles\n",
    "                \n",
    "#         def sample(self):\n",
    "#             return np.random.choice(range(self.n))\n",
    "        \n",
    "#         def contains(self,a):\n",
    "#             assert (type(a) == type(0)), 'Illegal action. Must be int.'\n",
    "#             return a < self.n\n",
    "        \n",
    "#     class ObservationSpace():\n",
    "        \n",
    "#         def __init__(self,feat_cols,actions_num):\n",
    "#             self.shape = 2*2 # two angles and it's velocity\n",
    "            \n",
    "#         def sample(self,data):\n",
    "#             pass                  #TODO\n",
    "        \n",
    "#         def contains(self,a):\n",
    "#             pass                  #TODO\n",
    "\n",
    "    def __init__(self, T = 100, gamma = 10, delta =10):\n",
    "        self.T = T\n",
    "        self.gamma = gamma  # velocity penalty \n",
    "        self.delta = delta  # acceleration penalty\n",
    "        \n",
    "    def reset(self, init_state_goal = None):\n",
    "        \n",
    "        if init_state_goal: self.state,self.goal = init_state\n",
    "        else: \n",
    "            self.goal = np.random.rand(2)*np.pi # angle coordinates of goal position\n",
    "            self.state = np.concatenate((self.goal + np.random.rand(2)*np.pi,np.zeros(2)))\n",
    "        self.done = False\n",
    "        self.t = 0\n",
    "        self.show = False\n",
    "        return self.state\n",
    "    \n",
    "    def move_goal(self):\n",
    "        # TODO implement moving goal \n",
    "        return self.goal\n",
    "    \n",
    "    def get_env_dynamic(self):\n",
    "        F = np.concatenate([np.eye(4),np.zeros([4,2])],axis=1) + \\\n",
    "            np.concatenate([np.zeros([4,2]),np.eye(4)],axis=1)\n",
    "        f = np.zeros(4)\n",
    "        \n",
    "        C = np.array(\n",
    "            [[1,0,0,0,0,0],\n",
    "             [0,1,0,0,0,0],\n",
    "             [0,0,self.gamma,0,0,0],\n",
    "             [0,0,0,self.gamma,0,0],\n",
    "             [0,0,0,0,self.delta,0],\n",
    "             [0,0,0,0,0,self.delta]])\n",
    "        c = np.array([-self.goal[0],-self.goal[1],0,0,0,0])\n",
    "        \n",
    "        return F,f,C,c\n",
    "    \n",
    "    def step(self,a):\n",
    "        if not self.done:\n",
    "            self.goal = self.move_goal() \n",
    "            F,f,C,c = self.get_env_dynamic()\n",
    "            xu  = np.concatenate([self.state,a])\n",
    "            self.state, reward = F.dot(xu) + f, -xu.T.dot(C).dot(xu) - c.dot(xu)\n",
    "            self.done = self.t >= self.T\n",
    "        else: reward = 0\n",
    "        self.t += 1\n",
    "        if self.show: self.render;\n",
    "        return self.state, reward, self.done, ''\n",
    "    \n",
    "    def render(self):\n",
    "        plt.clf();\n",
    "        fig, ax = plt.subplots();\n",
    "        ax.plot([0,np.sin(self.goal[0]),np.sin(self.goal[0])+np.sin(self.goal[:2].sum())],\n",
    "                 [0,np.cos(self.goal[0]),np.cos(self.goal[0])+np.cos(self.goal[:2].sum())],\n",
    "                'o-', color='999999', linewidth=7,markersize=12)\n",
    "        ax.plot([0,np.sin(self.state[0]),np.sin(self.state[0])+np.sin(self.state[:2].sum())],\n",
    "                 [0,np.cos(self.state[0]),np.cos(self.state[0])+np.cos(self.state[:2].sum())],\n",
    "                 'bo-', linewidth=5,markersize=10)\n",
    "#         ax.scatter(*env.goal,s=120,c='r')\n",
    "        ax.set_xlim([-2.2,2.2]);\n",
    "        ax.set_ylim([-2.2,2.2]);\n",
    "        ax.axis('off');        \n",
    "        return fig\n",
    "    \n",
    "    def sample_action(self):\n",
    "        return np.random.randn(2)*0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример, как работает среда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "env = RoboHand(T=20)\n",
    "env.reset()\n",
    "\n",
    "for t in range(env.T):\n",
    "    a = env.sample_action()\n",
    "    s,r,d,_ = env.step(a)\n",
    "    clear_output(wait=True)\n",
    "    display(env.render())\n",
    "    display(f'Step {t}. Reward {r}')\n",
    "    time.sleep(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lqr(x0,T,F,f,C,c):\n",
    "    '''\n",
    "    Plan best actions for T timesteps for linear environment\n",
    "    x0 (array) is initail position.\n",
    "    T (int) is time steps to plan number\n",
    "    F (numpy 2d array) env dynamic\n",
    "    f (numpy 1d array) env dynamic\n",
    "    C (numpy 2d array) env reward\n",
    "    f (numpy 1d array) env reward\n",
    "    \n",
    "    Returns list (length T) of best actions (each is 1d numpy array).\n",
    "    '''\n",
    "    \n",
    "    assert ((F.shape[0] == f.shape[0]) & (F.shape[1] == c.shape[0]) & \n",
    "            (C.shape[0] == c.shape[0]) & (C.shape[1] == c.shape[0]) & \n",
    "            (x0.shape[0] == f.shape[0])), 'F,f,C,c shape mismatch'\n",
    "    assert (x0.shape[0] < c.shape[0]), 'action dim mismatch'\n",
    "    \n",
    "    sd = x0.shape[0] #state_space dimesion\n",
    "    ad = c.shape[0] - f.shape[0] # action state_space dimesion\n",
    "    \n",
    "    a = np.zeros((T, ad))\n",
    "    \n",
    "    YOUR CODE HERE\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RoboHand(T=100, gamma= 100,delta=100)\n",
    "s = env.reset()\n",
    "a = lqr(s,env.T, *env.get_env_dynamic())\n",
    "\n",
    "for t in range(env.T):\n",
    "    s,r,d,_ = env.step(a[t])\n",
    "    clear_output(wait=True)\n",
    "    display(env.render())\n",
    "    display(f'Step {t}. Reward {r:.2f}. Action {a[t]}')\n",
    "    time.sleep(0.10)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание\n",
    "1. Реализовать LQR (2 балла).\n",
    "2. Допилить среду, чтобы нормально рисовалось ( +2 балла).\n",
    "3. Позапускать с разными наборами T, GAMMA, DELTA = [[20,0,0],[20,100,0],[20,0,100],[100,100,100]].\n",
    "4. Реализовать движущуюся цель. Переписать LQR, для меняющейся динамики (+3 балла).\n",
    "5. Реализовать ту же среду для 3х-мерного случая (+5 баллов). \n",
    "6. Реализовать тележку как линейную среду. Кост - отклонение позиции от нулевой, а угла штанги от вертикали. (+3 балла).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
